### **LUXDEVHQ 6-WEEK DATA PROGRAM GUIDE**

**Program Overview**

The LUXDEVHQ 6-Week Program is an intensive, hands-on learning experience designed to equip participants with essential skills in data analytics, data science, engineering, and machine learning. The program combines theory, practical labs, and real-world projects to ensure a comprehensive understanding of modern data tools and workflows.

**Program Start Date:**  
30th July 2025. 
First week (30th July to 4th July 2025) will be installtion, onboarding learners, and making sure they are aware of the tools and technologies that we will be using through out the program.

**Program Duration:**  
6 Weeks of intensive learning, followed by 2 months (optional) of internship. 

- During the internship, students will participate in real project development using the skills they have learned in the program, working with actual data and contributing to real-world solutions.

**Target Audience:**  
This program is designed for aspiring data analysts, data engineers, professionals seeking to upskill in analytics and automation, as well as entrepreneurs looking to make sense of their data.

**Delivery Mode:**  
Onsite (Live Sessions + Practical Labs)  
We believe in "learning by doing" — all sessions will involve hands-on activities and guided projects.

**Class Schedules:**
- **Day Classes:** 9:00 AM to 5:00 PM (Online and Physical Classes)  
  _Tip: Ideal for full-time learners who want immersive, instructor-led sessions._
- **Evening Classes:** 7:00 PM to 10:30 PM EAT (Online)  
  _Tip: Perfect for working professionals or those balancing other commitments._

---

### **WEEK 1: Excel, Power BI & SQL Fundamentals**

**Objective:**  
Build a solid foundation in essential data tools. Master how to clean, analyze, and visualize data effectively.

**Topics Covered:**
- **Excel basics:** Learn formulas, functions, pivot tables, charts, and lookups.  
  _Note: Excel is still the #1 business analysis tool worldwide!_
- **Power BI Introduction:** Build interactive dashboards and learn how to tell compelling data stories.
- **SQL Basics:** Understand how to extract and filter data using `SELECT`, `WHERE`, `ORDER BY`, and aggregations.

**Tools:**
- **Microsoft Excel** – for quick data analysis and cleaning.
- **Power BI Desktop** – to design and share dashboards.
- **MySQL / PostgreSQL** – foundational relational databases for storing and querying data.

 _By the end of Week 1, you'll confidently use Excel and Power BI, and write basic SQL queries._

---

### **WEEK 2: Introduction to Python for Data Analysis**

**Objective:**  
Introduce Python as a programming language for data analysis. Start coding from scratch!

**Topics Covered:**
- **Python basics:** Variables, loops, functions, and data types.
- **Working with data:** Pandas and NumPy for data manipulation.
- **Data cleaning:** Handle missing data, duplicates, and formatting issues.
- **Data visualization:** Create charts using Matplotlib and Seaborn.

**Tools:**
- **Python** – the most popular language in data science.
- **Jupyter Notebooks** – an interactive coding environment.
- **Pandas & NumPy** – powerful libraries for data handling.
- **Matplotlib & Seaborn** – tools to create beautiful charts.

 _By the end of Week 2, you'll write Python scripts to clean and visualize datasets._

 _Note: Python is used by top companies like Google, Netflix, and Spotify for data analysis!_

---

### **WEEK 3: Integrating SQL Databases with Python**

**Objective:**  
Combine Python with databases to perform advanced data extraction and analysis.

**Topics Covered:**
- **Connecting Python to databases:** Use `sqlite3`, `SQLAlchemy`, or `psycopg2`.
- **Writing SQL queries in Python:** Automate data extraction.
- **ETL Concepts:** Extract, Transform, Load — move and process data between systems.
- **Automating workflows:** Build small automations for data handling.

**Tools:**
- **Python**
- **PostgreSQL/MySQL**
- **SQLAlchemy** – ORM for connecting Python apps to databases.
- **Pandas** – for post-query data analysis.

_By the end of Week 3, you'll automate data retrieval and build mini data pipelines!_

_Tip: ETL is the backbone of all data engineering roles._

---

### **WEEK 4: Power BI Advanced & Working with Databases**

**Objective:**  
Advance your Power BI skills and integrate live data sources for dynamic reporting.

**Topics Covered:**
- **Advanced Power BI:** Use DAX formulas, create custom visuals, and work with parameters.
- **Connecting databases:** Build live dashboards connected to SQL databases.
- **Interactive reports:** Design dashboards with real-time data.
- **Sharing reports:** Publish reports to Power BI Service for team collaboration.

**Tools:**
- **Power BI Desktop & Power BI Service** – for building and sharing dashboards.
- **SQL Server / PostgreSQL** – as data sources.

 _By the end of Week 4, you'll design dynamic reports connected to live databases._

 _Tip: Power BI is a top skill for business intelligence roles globally._

---

### **WEEK 5: Introduction to Apache Airflow for Workflow Automation**

**Objective:**  
Automate data workflows and manage data pipelines effectively.

**Topics Covered:**
- **Introduction to Airflow:** Understand its purpose and use cases.
- **DAGs:** Design Directed Acyclic Graphs to control workflows.
- **Writing your first DAG:** Automate a sample data pipeline.
- **Monitoring workflows:** Learn scheduling, logging, and error handling.
- **Integration:** Connect Airflow to databases and APIs.

**Tools:**
- **Apache Airflow** – popular open-source workflow management tool.
- **Python**
- **PostgreSQL**
- **Docker (optional)** – containerization for easy deployment.

 _By the end of Week 5, you'll automate tasks and schedule data pipelines._

 _Tip: Airflow is heavily used by data engineers and data scientists alike!_

---

### **WEEK 6: Real-Time Data Processing with Apache Spark**

**Objective:**  
Learn big data processing and stream real-time data with Spark.

**Topics Covered:**
- **Big Data & Spark:** Understand Spark's role in handling massive datasets.
- **Spark architecture:** Learn about RDDs, DataFrames, and Spark SQL.
- **Real-time streaming:** Use Spark Structured Streaming for live data.
- **Integration with Kafka:** Optional — stream data from Kafka.
- **Analytics & ML use cases:** Understand Spark's application in machine learning.

**Tools:**
- **Apache Spark & PySpark** – powerful distributed computing engine.
- **Jupyter Notebooks**
- **Kafka (optional)**
- **Google Colab** – for cloud-based distributed computing.

_By the end of Week 6, you'll process large datasets and run real-time streaming jobs._

 _Tip: Spark powers big data at companies like Uber, Netflix, and Amazon._

---

### **After the Program: Internship & Project Development**

Following the learning phase, students will proceed to a **2-month internship**. During this time:
- Work on real-world projects under mentor guidance.
- Collaborate in teams to build production-level data solutions.
- Gain practical experience in data analytics, data engineering, and reporting.
- Build portfolio projects to showcase to potential employers.

_Goal: Ensure every student completes the program with tangible, real-world experience._

---
